# speech-emotion-recognition
 I’m excited to share the highlights of my second project ' Speech Emotion Recognition' completed during my internship at @Zidio Development.

In this project, I delved into the world of emotional speech recognition, applying deep learning techniques. I worked with the Toronto Emotional Speech Set (TESS) dataset, which includes 2800 audio files, each labeled with an emotion.

Leveraging Python and key libraries like Librosa, TensorFlow, Keras, and scikit-learn, I developed and fine-tuned both an LSTM (Long Short-Term Memory) model and a CNN (Convolutional Neural Network) model to classify emotions from speech signals. The models were trained on 2240 audio files and evaluated on 560 files.

The models achieved an impressive 97% accuracy on the test set. To better understand the performance, I visualized the results with confusion matrices and classification reports.

This project has promising applications in fields such as human-computer interaction, sentiment analysis, and mental health diagnosis. I’m eager to share my insights and experiences with the LinkedIn community
